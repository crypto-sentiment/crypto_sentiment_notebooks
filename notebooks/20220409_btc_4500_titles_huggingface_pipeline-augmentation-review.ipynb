{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb735e5",
   "metadata": {},
   "source": [
    "#### Author\n",
    "Zalina Rusinova\n",
    "\n",
    "#### Reference\n",
    "[Notion ticket](https://www.notion.so/a74951e4e815480584dea7d61ddce6cc?v=dbfdb1207d0e451b827d3c5041ed0cfd&p=141d322a8f1a421fbb801755ea55caec)\n",
    "\n",
    "#### Idea\n",
    "Test different ways of data augmentation \n",
    "\n",
    "#### Data\n",
    "4500 cryptonews titles labeled as positive, neutral or negative â€“ zipped pwd-protected [CSV](https://drive.google.com/file/d/1Apr3YPZVf0kOJ5Pc1RYDoQxTdjJPbnt4/view?usp=sharing) (not to be shared outside of the project!)\n",
    "\n",
    "#### Result\n",
    "So far, it has not been possible to achieve an increase in accuracy by any of tried methods of data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36fa5713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/victor/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/victor/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (\n",
    "    TrainingArguments, Trainer, \n",
    "    AdamW, get_scheduler,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from importlib import import_module\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from typing import Dict, Any, Tuple, List, Union, Callable\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer as Pl_trainer\n",
    "from pytorch_lightning import seed_everything, Callback\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.INFO)\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca74c4e",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba782640",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/20190110_train_4500.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "943a6ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "062f24a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bitcoin Market Has Run Out of Juice: Cryptocur...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitcoin Core 0.14.0 Speeds Up Blockchain Synci...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thinking of Travelling With Bitcoin? With Thes...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Investors Carried Out Mental Gymnastics to Jus...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bitcoin Price Holds Above $8,500 as Market Fig...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title sentiment\n",
       "0  Bitcoin Market Has Run Out of Juice: Cryptocur...  Negative\n",
       "1  Bitcoin Core 0.14.0 Speeds Up Blockchain Synci...  Positive\n",
       "2  Thinking of Travelling With Bitcoin? With Thes...  Positive\n",
       "3  Investors Carried Out Mental Gymnastics to Jus...  Negative\n",
       "4  Bitcoin Price Holds Above $8,500 as Market Fig...  Positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7518e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "dataset[\"label\"] = le.fit_transform(dataset[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bceadc",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2abc6728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_object(\n",
    "    object_cfg: Dict[str, Any], \n",
    "    is_hugging_face: bool = False, \n",
    "    **kwargs: Dict[str, Any]\n",
    ") -> Callable:\n",
    "    if \"class\" not in object_cfg.keys():\n",
    "        raise ValueError(\"class key schould be in config\")\n",
    "\n",
    "    if \"params\" in object_cfg.keys():\n",
    "        params = object_cfg[\"params\"]\n",
    "\n",
    "        for key, val in params.items():\n",
    "            kwargs[key] = val\n",
    "    else:\n",
    "        params = {}\n",
    "    \n",
    "    if is_hugging_face:\n",
    "        return get_instance(object_cfg[\"class\"]).from_pretrained(**kwargs)\n",
    "    \n",
    "    return get_instance(object_cfg[\"class\"])(**kwargs)\n",
    "\n",
    "\n",
    "def get_instance(object_path: str) -> Callable:\n",
    "\n",
    "    module_path, class_name = object_path.rsplit(\".\", 1)\n",
    "    module = import_module(module_path)\n",
    "\n",
    "    return getattr(module, class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bda47000",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_str = \"\"\"\n",
    "training_args:\n",
    "    class: transformers.TrainingArguments\n",
    "    params:\n",
    "        output_dir: './test_trainer'\n",
    "        num_train_epochs: 3\n",
    "        per_device_train_batch_size: 32\n",
    "        per_device_eval_batch_size: 64\n",
    "        warmup_steps: 500                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
    "        weight_decay: 0.001\n",
    "        logging_steps: 10\n",
    "        evaluation_strategy: epoch\n",
    "        learning_rate: 0.00003\n",
    "\n",
    "\n",
    "model_name: &model_name distilbert-base-uncased\n",
    "\n",
    "tokenizer:\n",
    "    class: transformers.DistilBertTokenizer\n",
    "    params:\n",
    "        pretrained_model_name_or_path: *model_name\n",
    "\n",
    "model:\n",
    "    class: transformers.DistilBertForSequenceClassification\n",
    "    params:\n",
    "        pretrained_model_name_or_path: *model_name\n",
    "        num_labels: 3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0b9edc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = yaml.safe_load(cfg_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c9eba2",
   "metadata": {},
   "source": [
    "### Preprocess/split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daefb757",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinNewsDataset(Dataset):\n",
    "    def __init__(self, encodings: Dict[str, Any], labels: list):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        \n",
    "        return item\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a85c7025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(cfg: Dict[str, Any], data: pd.Series, labels: pd.Series) -> Dataset:\n",
    "    \n",
    "    tokenizer = build_object(cfg[\"tokenizer\"], is_hugging_face=True)\n",
    "    \n",
    "    encodings = tokenizer(data.values.tolist(), truncation=True, padding=True)\n",
    "    \n",
    "    return FinNewsDataset(encodings, labels.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a0d31c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(dataset: pd.DataFrame, test_size: float = 0.2) -> Tuple[list, ...]:\n",
    "    train_data, val_data, train_labels, val_labels = train_test_split(\n",
    "        dataset, \n",
    "        dataset[\"label\"],\n",
    "        test_size=test_size\n",
    "    )\n",
    "    \n",
    "    return train_data, val_data, train_labels, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cace9d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, train_labels, val_labels = split_train_val(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ef2589",
   "metadata": {},
   "source": [
    "## Augmentation of training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a81a510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augs(\n",
    "    augmenter,\n",
    "    data: pd.DataFrame,\n",
    "    augs_frac: float = 0.1,\n",
    "    aug_kwargs: Dict[str, Any] = {},\n",
    "    mult_aug: bool = False\n",
    ")-> pd.DataFrame:\n",
    "    \n",
    "\n",
    "    samples_to_augment = data.sample(frac=augs_frac)\n",
    "    \n",
    "    if mult_aug:\n",
    "        \n",
    "        aug_data = []\n",
    "        \n",
    "        for i in range(len(samples_to_augment)):\n",
    "            aug_result = augmenter.augment(samples_to_augment.iloc[i][\"title\"], **aug_kwargs)\n",
    "\n",
    "            assert (aug_result) != list, \"Aug result should be list\"\n",
    "\n",
    "            for line in aug_result:\n",
    "                aug_data.append(line)\n",
    "    \n",
    "        aug_labels = [entry for entry in samples_to_augment[\"label\"] for _ in range(aug_kwargs[\"n\"])]\n",
    "    else:\n",
    "        aug_data = augmenter.augment(samples_to_augment[\"title\"].tolist())\n",
    "        aug_labels = samples_to_augment[\"label\"]\n",
    "\n",
    "    augs_df = pd.DataFrame({\"title\": aug_data, \"label\": aug_labels})\n",
    "    \n",
    "    result = shuffle(data.append(augs_df).reset_index(drop=True))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d5a383",
   "metadata": {},
   "source": [
    "### 1. Back Translation Augmenter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aefcdd3",
   "metadata": {},
   "source": [
    "Back-translation is translating target language to source language and mixing both original source sentence and back-translated sentence to train a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e59a460",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_translation_aug = naw.BackTranslationAug(\n",
    "    from_model_name=\"facebook/wmt19-en-de\", \n",
    "    to_model_name=\"facebook/wmt19-de-en\",\n",
    "    device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3376e05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.4 s, sys: 108 ms, total: 12.5 s\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "back_translation_data = get_augs(back_translation_aug, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f771bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>Australia: Tax Regulator Warns of Fraudulent R...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>Bitcoin Price Watch; Here Are Two Trades For T...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>Final Frontier? William Shatner Boldly Goes in...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>January 14th Will be Known as ;Bitcoin Cash Ch...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Reddit to Relaunch Bitcoin Payments (And Add M...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title sentiment  label\n",
       "680   Australia: Tax Regulator Warns of Fraudulent R...  Negative      0\n",
       "2070  Bitcoin Price Watch; Here Are Two Trades For T...   Neutral      1\n",
       "471   Final Frontier? William Shatner Boldly Goes in...  Positive      2\n",
       "2663  January 14th Will be Known as ;Bitcoin Cash Ch...   Neutral      1\n",
       "1998  Reddit to Relaunch Bitcoin Payments (And Add M...   Neutral      1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_translation_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9789756",
   "metadata": {},
   "source": [
    "### 2. Synonym Augmenter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ce70c5",
   "metadata": {},
   "source": [
    "Substitute word by WordNet's synonym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e341a271",
   "metadata": {},
   "source": [
    "In this example generating 2 augmented sentences with 3 synonyms (this parameters can be changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "17014e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_aug = naw.SynonymAug(aug_src='wordnet', aug_max=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4aca6526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 861 ms, sys: 12.2 ms, total: 873 ms\n",
      "Wall time: 857 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "synonyms_data = get_augs(synonym_aug, train_data, aug_kwargs={\"n\": 2}, mult_aug=True, augs_frac=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0a5ab31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5101, 3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5345eaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>Why Major Crypto Exchanges are Granting Bitcoi...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>Former FDIC Chair: BitcoinPolicies Shouldn't '...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Arizona Bitcoin Trader Convicted for Crypto Mo...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>Politician Ron Paul: US Government Should 'Sta...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4964</th>\n",
       "      <td>Bitcoins White person Paper: The Blueprint for...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title sentiment  label\n",
       "1737  Why Major Crypto Exchanges are Granting Bitcoi...   Neutral      1\n",
       "2399  Former FDIC Chair: BitcoinPolicies Shouldn't '...   Neutral      1\n",
       "286   Arizona Bitcoin Trader Convicted for Crypto Mo...  Negative      0\n",
       "936   Politician Ron Paul: US Government Should 'Sta...  Negative      0\n",
       "4964  Bitcoins White person Paper: The Blueprint for...       NaN      1"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e50a37f",
   "metadata": {},
   "source": [
    "## Train pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bd81d8",
   "metadata": {},
   "source": [
    "### Hugging Face api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6e3ecc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_huggin_face_pipeline( \n",
    "    cfg,\n",
    "    train_dataset: Dataset, \n",
    "    val_dataset: Dataset\n",
    "):\n",
    "    \n",
    "    model = build_object(cfg[\"model\"], is_hugging_face=True)\n",
    "    \n",
    "    training_args = build_object(cfg[\"training_args\"])\n",
    "    \n",
    "    metric = load_metric(\"accuracy\")\n",
    "    \n",
    "    def compute_metrics(eval_pred: tuple) -> dict:\n",
    "    \n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "        return metric.compute(predictions=predictions, references=labels)\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cae9a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_val_dataset = prepare_dataset(cfg, val_data[\"title\"], val_data[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54cb079",
   "metadata": {},
   "source": [
    "**baseline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cc816215",
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_train_dataset = prepare_dataset(cfg, train_data[\"title\"], train_data[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "38e5af46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='342' max='342' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [342/342 00:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.945100</td>\n",
       "      <td>0.888755</td>\n",
       "      <td>0.673985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.643200</td>\n",
       "      <td>0.575787</td>\n",
       "      <td>0.774973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.481900</td>\n",
       "      <td>0.529932</td>\n",
       "      <td>0.796926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_huggin_face_pipeline(cfg, hg_train_dataset, hg_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d559f916",
   "metadata": {},
   "source": [
    "**back translation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d880dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_train_dataset = prepare_dataset(cfg, back_translation_data[\"title\"], back_translation_data[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4ed34da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='378' max='378' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [378/378 00:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.891800</td>\n",
       "      <td>0.830054</td>\n",
       "      <td>0.688255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.547700</td>\n",
       "      <td>0.562562</td>\n",
       "      <td>0.785950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.465300</td>\n",
       "      <td>0.579991</td>\n",
       "      <td>0.783754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_huggin_face_pipeline(cfg, hg_train_dataset, hg_val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b95818",
   "metadata": {},
   "source": [
    "**synonyms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "30937bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_train_dataset = prepare_dataset(cfg, synonyms_data[\"title\"], synonyms_data[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a334bb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [480/480 00:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.770500</td>\n",
       "      <td>0.716458</td>\n",
       "      <td>0.726674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.491400</td>\n",
       "      <td>0.568339</td>\n",
       "      <td>0.788145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.409800</td>\n",
       "      <td>0.524468</td>\n",
       "      <td>0.807903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_huggin_face_pipeline(cfg, hg_train_dataset, hg_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64665252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
